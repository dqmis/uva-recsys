{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8dae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominykas.seputis/github/uva-recsys/.venv/lib/python3.11/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'\n",
      "  warn(f\"Triton dtype mappings did not load successfully due to an error: {exc.msg}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import *\n",
    "from merlin.schema.tags import Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3206b3f",
   "metadata": {},
   "source": [
    "### Define Input/Output Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b132a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = \"../../../data/ebnerd_demo_modified/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105dd71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{INPUT_DATA_DIR}/all.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22bca5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change impression_ts granularity to day and convert to timestamp\n",
    "df[\"impression_ts\"] = pd.to_datetime(df[\"impression_ts\"], unit=\"s\").dt.floor(\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a256f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominykas.seputis/github/uva-recsys/.venv/lib/python3.11/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "/Users/dominykas.seputis/github/uva-recsys/.venv/lib/python3.11/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "/Users/dominykas.seputis/github/uva-recsys/.venv/lib/python3.11/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "SESSIONS_MAX_LENGTH = 10\n",
    "\n",
    "# Categorify categorical features\n",
    "categ_feats = ['article_id', 'article_is_premium', 'article_type', 'article_category'] >> nvt.ops.Categorify()\n",
    "\n",
    "# Define Groupby Workflow\n",
    "groupby_feats = categ_feats + ['user_id', 'impression_ts', 'article_read_time', 'article_total_read_time', 'article_sentiment', 'article_ctr', 'article_emb']\n",
    "\n",
    "# Group interaction features by session\n",
    "groupby_features = groupby_feats >> nvt.ops.Groupby(\n",
    "    groupby_cols=[\"user_id\"],\n",
    "    aggs={\n",
    "        \"article_id\": [\"list\", \"count\"],\n",
    "        \"article_is_premium\": [\"list\"],\n",
    "        \"article_type\": [\"list\"],\n",
    "        \"article_category\": [\"list\"],\n",
    "        \"article_read_time\": [\"list\"],\n",
    "        \"article_total_read_time\": [\"list\"],\n",
    "        \"article_sentiment\": [\"list\"],\n",
    "        \"article_ctr\": [\"list\"],\n",
    "        \"article_emb\": [\"list\"],\n",
    "        \"impression_ts\": [\"first\"],\n",
    "        },\n",
    "    name_sep=\"-\")\n",
    "\n",
    "\n",
    "sequence_features_truncated_item = (\n",
    "    groupby_features['article_id-list']\n",
    "    >> nvt.ops.ListSlice(-SESSIONS_MAX_LENGTH)\n",
    "    >> TagAsItemID()\n",
    ")\n",
    "\n",
    "sequence_features_truncated_cat = (\n",
    "    groupby_features['article_is_premium-list', 'article_type-list', 'article_category-list']\n",
    "    >> nvt.ops.ListSlice(-SESSIONS_MAX_LENGTH)\n",
    "    >> nvt.ops.AddMetadata(tags=[Tags.CATEGORICAL])\n",
    ")\n",
    "sequence_features_truncated_cont = (\n",
    "    groupby_features['article_read_time-list', 'article_total_read_time-list', 'article_sentiment-list', 'article_ctr-list']\n",
    "    >> nvt.ops.ListSlice(-SESSIONS_MAX_LENGTH)\n",
    "    >> nvt.ops.AddMetadata(tags=[Tags.CONTINUOUS])\n",
    ")\n",
    "sequence_features_truncated_emb = (\n",
    "    groupby_features['article_emb-list']\n",
    "    >> nvt.ops.ListSlice(-SESSIONS_MAX_LENGTH)\n",
    "    >> nvt.ops.AddMetadata(tags=[Tags.EMBEDDING])\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Filter out sessions with length 1 (not valid for next-item prediction training and evaluation)\n",
    "MINIMUM_SESSION_LENGTH = 2\n",
    "selected_features = (\n",
    "    groupby_features['article_id-count', 'impression_ts-first', 'user_id'] +\n",
    "    sequence_features_truncated_item +\n",
    "    sequence_features_truncated_cat +\n",
    "    sequence_features_truncated_cont +\n",
    "    sequence_features_truncated_emb\n",
    ")\n",
    "\n",
    "filtered_sessions = selected_features >> nvt.ops.Filter(f=lambda df: df[\"article_id-count\"] >= MINIMUM_SESSION_LENGTH)\n",
    "\n",
    "seq_feats_list = filtered_sessions['article_id-list', 'article_is_premium-list', 'article_type-list', 'article_category-list', 'article_read_time-list', 'article_total_read_time-list', 'article_sentiment-list', 'article_ctr-list', 'article_emb-list'] >>  nvt.ops.ValueCount()\n",
    "\n",
    "workflow = nvt.Workflow(filtered_sessions['user_id', 'impression_ts-first'] + seq_feats_list)\n",
    "\n",
    "dataset = nvt.Dataset(df)\n",
    "\n",
    "# Generate statistics for the features and export parquet files\n",
    "# this step will generate the schema file\n",
    "workflow.fit_transform(dataset).to_parquet(os.path.join(INPUT_DATA_DIR, \"processed_nvt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2458c28f",
   "metadata": {},
   "source": [
    "It is possible to save the preprocessing workflow. That is useful to apply the same preprocessing to other data (with the same schema) and also to deploy the session-based recommendation pipeline to Triton Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78e42cbf-edd6-44af-af23-c026edb578c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_id</td>\n",
       "      <td>()</td>\n",
       "      <td>DType(name='uint32', element_type=&lt;ElementType...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>impression_ts-first</td>\n",
       "      <td>()</td>\n",
       "      <td>DType(name='datetime64[ns]', element_type=&lt;Ele...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article_id-list</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL, Tags.LIST, Tags.ID)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.article_id.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5835.0</td>\n",
       "      <td>article_id</td>\n",
       "      <td>5836.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>article_is_premium-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.article_is_premium.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>article_is_premium</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>article_type-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.article_type.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>article_type</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>article_category-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.article_category.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>article_category</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>article_read_time-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>article_total_read_time-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float32', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>article_sentiment-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float32', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>article_ctr-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>article_emb-list</td>\n",
       "      <td>(Tags.EMBEDDING, Tags.LIST)</td>\n",
       "      <td>DType(name='float32', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'user_id', 'tags': set(), 'properties': {}, 'dtype': DType(name='uint32', element_type=<ElementType.UInt: 'uint'>, element_size=32, element_unit=None, signed=None, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'impression_ts-first', 'tags': set(), 'properties': {}, 'dtype': DType(name='datetime64[ns]', element_type=<ElementType.DateTime: 'datetime'>, element_size=64, element_unit=<ElementUnit.Nanosecond: 'nanosecond'>, signed=None, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'article_id-list', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>, <Tags.ID: 'id'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.article_id.parquet', 'domain': {'min': 0, 'max': 5835, 'name': 'article_id'}, 'embedding_sizes': {'cardinality': 5836, 'dimension': 206}, 'value_count': {'min': 2, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=2, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'article_is_premium-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.article_is_premium.parquet', 'domain': {'min': 0, 'max': 4, 'name': 'article_is_premium'}, 'embedding_sizes': {'cardinality': 5, 'dimension': 16}, 'value_count': {'min': 2, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=2, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'article_type-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.article_type.parquet', 'domain': {'min': 0, 'max': 13, 'name': 'article_type'}, 'embedding_sizes': {'cardinality': 14, 'dimension': 16}, 'value_count': {'min': 2, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=2, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'article_category-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.article_category.parquet', 'domain': {'min': 0, 'max': 23, 'name': 'article_category'}, 'embedding_sizes': {'cardinality': 24, 'dimension': 16}, 'value_count': {'min': 2, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=2, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'article_read_time-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 2, 'max': 10}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=2, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'article_total_read_time-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 2, 'max': 10}}, 'dtype': DType(name='float32', element_type=<ElementType.Float: 'float'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=2, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'article_sentiment-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 2, 'max': 10}}, 'dtype': DType(name='float32', element_type=<ElementType.Float: 'float'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=2, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'article_ctr-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 2, 'max': 10}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=2, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'article_emb-list', 'tags': {<Tags.EMBEDDING: 'embedding'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 2, 'max': 10}}, 'dtype': DType(name='float32', element_type=<ElementType.Float: 'float'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=2, max=10)))), 'is_list': True, 'is_ragged': True}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.output_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b54bb-4549-49a3-89bb-1f573a426aca",
   "metadata": {},
   "source": [
    "Save NVTabular workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f498dce-69eb-4f88-8ddd-8629558825df",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.save(os.path.join(INPUT_DATA_DIR, \"workflow_etl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a41961",
   "metadata": {},
   "source": [
    "## Export pre-processed data by day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cedca3",
   "metadata": {},
   "source": [
    "In this example we are going to split the preprocessed parquet files by days, to allow for temporal training and evaluation. There will be a folder for each day and three parquet files within each day folder: `train.parquet`, `validation.parquet` and `test.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d3e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\",os.path.join(INPUT_DATA_DIR, \"sessions_by_ts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "603fb27a-0c64-43eb-be79-42213944990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the processed parquet file\n",
    "sessions_gdf = pd.read_parquet(os.path.join(INPUT_DATA_DIR, \"processed_nvt/part_0.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c537a248-059e-4db9-8b62-9681175f0193",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id impression_ts-first  \\\n",
      "0    11313          2023-04-27   \n",
      "1    13538          2023-04-27   \n",
      "2    15430          2023-05-02   \n",
      "\n",
      "                                     article_id-list  \\\n",
      "0  [2177, 220, 708, 642, 1111, 384, 1485, 1083, 1...   \n",
      "1  [1448, 1914, 577, 114, 329, 679, 935, 303, 713...   \n",
      "2   [1469, 64, 2068, 64, 2068, 793, 1693, 2172, 514]   \n",
      "\n",
      "          article_is_premium-list               article_type-list  \\\n",
      "0  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]   \n",
      "1  [3, 4, 3, 3, 3, 4, 3, 3, 3, 3]  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]   \n",
      "2     [3, 3, 3, 3, 3, 3, 3, 4, 4]     [3, 3, 3, 3, 3, 3, 3, 3, 3]   \n",
      "\n",
      "            article_category-list  \\\n",
      "0  [6, 3, 7, 8, 5, 8, 8, 3, 3, 3]   \n",
      "1  [6, 3, 6, 6, 3, 3, 9, 5, 5, 4]   \n",
      "2     [3, 3, 3, 3, 3, 3, 3, 6, 6]   \n",
      "\n",
      "                              article_read_time-list  \\\n",
      "0  [8.0, 25.0, 36.0, 18.0, 16.0, 15.0, 15.0, 526....   \n",
      "1  [9.0, 109.0, 9.0, 9.0, 16.0, 14.0, 26.0, 26.0,...   \n",
      "2  [101.0, 32.0, 70.0, 12.0, 136.0, 75.0, 16.0, 2...   \n",
      "\n",
      "                        article_total_read_time-list  \\\n",
      "0  [1913402.0, 10583023.0, 3688117.0, 4797681.0, ...   \n",
      "1  [5773352.0, 1917593.0, 4141368.0, 5024503.0, 5...   \n",
      "2  [4896058.0, 18475896.0, 3255359.0, 18475896.0,...   \n",
      "\n",
      "                              article_sentiment-list  \\\n",
      "0  [0.8309999704360962, 0.6765000224113464, 0.981...   \n",
      "1  [0.753600001335144, 0.697700023651123, 0.88010...   \n",
      "2  [0.7199000120162964, 0.9366000294685364, 0.882...   \n",
      "\n",
      "                                    article_ctr-list  \\\n",
      "0  [0.15462177634721863, 0.2259148850156692, 0.22...   \n",
      "1  [0.22039473684210525, 0.0572683537026449, 0.25...   \n",
      "2  [0.270218910677321, 0.20628242846209574, 0.205...   \n",
      "\n",
      "                                    article_emb-list  \n",
      "0  [[-0.13696848, 0.12694848, -0.37462023, 0.1398...  \n",
      "1  [[-0.03582789, 0.09175368, -0.15060574, 0.0744...  \n",
      "2  [[-0.17292447, 0.08093449, -0.10759985, 0.0820...  \n"
     ]
    }
   ],
   "source": [
    "print(sessions_gdf.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c67a92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominykas.seputis/github/uva-recsys/.venv/lib/python3.11/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "object too deep for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers4rec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_time_based_splits\n\u001b[0;32m----> 5\u001b[0m \u001b[43msave_time_based_splits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnvt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msessions_gdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpartition_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimpression_ts-first\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtimestamp_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/uva-recsys/.venv/lib/python3.11/site-packages/transformers4rec/utils/data_utils.py:206\u001b[0m, in \u001b[0;36msave_time_based_splits\u001b[0;34m(data, output_dir, partition_col, timestamp_col, test_size, val_size, overwrite, cpu)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Split a dataset into time-based splits.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03mNote, this function requires Rapids dependencies to be installed:\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03mcudf, cupy and dask_cudf\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    Whether or not to run the computation on the CPU.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cpu:\n\u001b[0;32m--> 206\u001b[0m     \u001b[43m_save_time_based_splits_cpu\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimestamp_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _save_time_based_splits_gpu(\n\u001b[1;32m    217\u001b[0m     data,\n\u001b[1;32m    218\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39moverwrite,\n\u001b[1;32m    224\u001b[0m )\n",
      "File \u001b[0;32m~/github/uva-recsys/.venv/lib/python3.11/site-packages/transformers4rec/utils/data_utils.py:359\u001b[0m, in \u001b[0;36m_save_time_based_splits_cpu\u001b[0;34m(data, output_dir, partition_col, timestamp_col, test_size, val_size, overwrite)\u001b[0m\n\u001b[1;32m    356\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(output_dir)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m tmpdirname:\n\u001b[0;32m--> 359\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmpdirname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     time_dirs \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(tmpdirname)) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mstartswith(partition_col[\u001b[38;5;241m0\u001b[39m])]\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m tqdm(time_dirs, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating time-based splits\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/github/uva-recsys/.venv/lib/python3.11/site-packages/merlin/io/dataset.py:982\u001b[0m, in \u001b[0;36mDataset.to_parquet\u001b[0;34m(self, output_path, shuffle, preserve_files, output_files, out_files_per_proc, row_group_size, num_threads, dtypes, cats, conts, labels, suffix, partition_on, method, write_hugectr_keyset)\u001b[0m\n\u001b[1;32m    979\u001b[0m tf_metadata\u001b[38;5;241m.\u001b[39mto_json_file(metadata_path)\n\u001b[1;32m    981\u001b[0m \u001b[38;5;66;03m# Output dask_cudf DataFrame to dataset\u001b[39;00m\n\u001b[0;32m--> 982\u001b[0m \u001b[43m_ddf_to_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mddf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_files_per_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_group_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrite_hugectr_keyset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/uva-recsys/.venv/lib/python3.11/site-packages/merlin/io/dask.py:424\u001b[0m, in \u001b[0;36m_ddf_to_dataset\u001b[0;34m(ddf, fs, output_path, shuffle, file_partition_map, out_files_per_proc, cat_names, cont_names, label_names, output_format, num_threads, cpu, suffix, row_group_size, partition_on, schema)\u001b[0m\n\u001b[1;32m    422\u001b[0m     out \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcompute(out)\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 424\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mdask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msynchronous\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached_writers:\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;66;03m# Follow-up Shuffling and _metadata creation\u001b[39;00m\n\u001b[1;32m    428\u001b[0m     _finish_dataset(client, ddf, output_path, fs, output_format, cpu, schema)\n",
      "File \u001b[0;32m~/github/uva-recsys/.venv/lib/python3.11/site-packages/dask/base.py:665\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 665\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/github/uva-recsys/.venv/lib/python3.11/site-packages/merlin/core/dispatch.py:69\u001b[0m, in \u001b[0;36mannotate.<locals>.inner1.<locals>.inner2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner2\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/uva-recsys/.venv/lib/python3.11/site-packages/merlin/io/dask.py:157\u001b[0m, in \u001b[0;36m_write_partitioned\u001b[0;34m(df, filename, output_path, partition_cols, shuffle, fs, cat_names, cont_names, label_names, output_format, num_threads, cpu, row_group_size)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data left to save outside partition columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Partition the input data\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m fns, dfs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_partition_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m writer \u001b[38;5;241m=\u001b[39m writer_factory(\n\u001b[1;32m    159\u001b[0m     output_format,\n\u001b[1;32m    160\u001b[0m     output_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m     row_group_size\u001b[38;5;241m=\u001b[39mrow_group_size,\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    168\u001b[0m writer\u001b[38;5;241m.\u001b[39mset_col_names(labels\u001b[38;5;241m=\u001b[39mlabel_names, cats\u001b[38;5;241m=\u001b[39mcat_names, conts\u001b[38;5;241m=\u001b[39mcont_names)\n",
      "File \u001b[0;32m~/github/uva-recsys/.venv/lib/python3.11/site-packages/merlin/io/dask.py:110\u001b[0m, in \u001b[0;36m_get_partition_groups\u001b[0;34m(df, partition_cols, fs, output_path, filename)\u001b[0m\n\u001b[1;32m    108\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(partition_cols)\n\u001b[1;32m    109\u001b[0m divisions \u001b[38;5;241m=\u001b[39m df[partition_cols]\u001b[38;5;241m.\u001b[39mdrop_duplicates(ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 110\u001b[0m splits \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearchsorted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdivisions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m splits \u001b[38;5;241m=\u001b[39m splits\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mlen\u001b[39m(df[partition_cols])]\n\u001b[1;32m    113\u001b[0m subgroups, fns \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mValueError\u001b[0m: object too deep for desired array"
     ]
    }
   ],
   "source": [
    "from transformers4rec.utils.data_utils import save_time_based_splits\n",
    "\n",
    "\n",
    "\n",
    "save_time_based_splits(data=nvt.Dataset(sessions_gdf),\n",
    "                       output_dir= OUTPUT_DIR,\n",
    "                       partition_col='impression_ts-first',\n",
    "                       timestamp_col='user_id',\n",
    "                       cpu=True,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72337b",
   "metadata": {},
   "source": [
    "## Check out the preprocessed outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd04ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATHS = os.path.join(OUTPUT_DIR, \"1\", \"train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e5e6358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id-list</th>\n",
       "      <th>category-list</th>\n",
       "      <th>age_days-list</th>\n",
       "      <th>weekday_sin-list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70000</td>\n",
       "      <td>[306, 5, 40, 17]</td>\n",
       "      <td>[104, 3, 12, 6]</td>\n",
       "      <td>[0.044022594, 0.34956282, 0.7326993, 0.09403495]</td>\n",
       "      <td>[0.7417527, 0.60325843, 0.07417604, 0.28911334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70001</td>\n",
       "      <td>[43, 20, 69, 8, 57]</td>\n",
       "      <td>[13, 6, 21, 3, 16]</td>\n",
       "      <td>[0.8072543, 0.28916782, 0.04966254, 0.08417622...</td>\n",
       "      <td>[0.7995051, 0.86722755, 0.84298295, 0.15793765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002</td>\n",
       "      <td>[137, 35, 37, 85, 65, 5]</td>\n",
       "      <td>[37, 10, 11, 22, 18, 3]</td>\n",
       "      <td>[0.04696693, 0.94499177, 0.2922437, 0.83047426...</td>\n",
       "      <td>[0.72519076, 0.92308444, 0.40120387, 0.3821016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70007</td>\n",
       "      <td>[28, 9, 153, 74, 53, 15, 173]</td>\n",
       "      <td>[9, 4, 39, 20, 15, 5, 46]</td>\n",
       "      <td>[0.4730765, 0.69885534, 0.034774363, 0.7225920...</td>\n",
       "      <td>[0.33613566, 0.660022, 0.72897774, 0.66087157,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70021</td>\n",
       "      <td>[59, 32, 11, 21, 23, 23, 9, 15]</td>\n",
       "      <td>[17, 10, 7, 7, 8, 8, 4, 5]</td>\n",
       "      <td>[0.07898139, 0.27463168, 0.1885847, 0.5203435,...</td>\n",
       "      <td>[0.39734098, 0.74895114, 0.43540764, 0.8372503...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                     item_id-list               category-list  \\\n",
       "0       70000                 [306, 5, 40, 17]             [104, 3, 12, 6]   \n",
       "1       70001              [43, 20, 69, 8, 57]          [13, 6, 21, 3, 16]   \n",
       "2       70002         [137, 35, 37, 85, 65, 5]     [37, 10, 11, 22, 18, 3]   \n",
       "4       70007    [28, 9, 153, 74, 53, 15, 173]   [9, 4, 39, 20, 15, 5, 46]   \n",
       "5       70021  [59, 32, 11, 21, 23, 23, 9, 15]  [17, 10, 7, 7, 8, 8, 4, 5]   \n",
       "\n",
       "                                       age_days-list  \\\n",
       "0   [0.044022594, 0.34956282, 0.7326993, 0.09403495]   \n",
       "1  [0.8072543, 0.28916782, 0.04966254, 0.08417622...   \n",
       "2  [0.04696693, 0.94499177, 0.2922437, 0.83047426...   \n",
       "4  [0.4730765, 0.69885534, 0.034774363, 0.7225920...   \n",
       "5  [0.07898139, 0.27463168, 0.1885847, 0.5203435,...   \n",
       "\n",
       "                                    weekday_sin-list  \n",
       "0    [0.7417527, 0.60325843, 0.07417604, 0.28911334]  \n",
       "1  [0.7995051, 0.86722755, 0.84298295, 0.15793765...  \n",
       "2  [0.72519076, 0.92308444, 0.40120387, 0.3821016...  \n",
       "4  [0.33613566, 0.660022, 0.72897774, 0.66087157,...  \n",
       "5  [0.39734098, 0.74895114, 0.43540764, 0.8372503...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(TRAIN_PATHS)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a687f998-8905-42a4-bb92-d1f5244860b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6461a96",
   "metadata": {},
   "source": [
    "You have  just created session-level features to train a session-based recommendation model using NVTabular. Now you can move to the the next notebook,`02-session-based-XLNet-with-PyT.ipynb` to train a session-based recommendation model using [XLNet](https://arxiv.org/abs/1906.08237), one of the state-of-the-art NLP model. Please shut down this kernel to free the GPU memory before you start the next one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d795d7ca5d3ec3bd6293cc80853205a74ce23d484a2b8f537732a716747107c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
